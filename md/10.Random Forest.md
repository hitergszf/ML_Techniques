# Random Forest

### 一、Random Forest Algorithm

1. 想到tree就会想到森林，我们试图用aggregation of aggregation来提高算法的效果。

   ![image-20200218152712352](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200218152712352.png)

   对比一下，由于数据量有限，我们使用boostrap来随机取样得到$N'$大小的样本然后学习出一颗decision tree然后再对每一棵树做uniform vote，bagging然后就得到了最后的G

   <font color = red>注意我们这里用的是 **fully grown**的tree而不是通过剪枝得到的树，实际上加入剪枝操作会效果更好，这里我们就考虑randomness这一点上我们可以改善多个树的作用</font>

2. 我们此处使用的RF算法实际上是取了样本的一个随机的子空间来形成树所以总结出RF的特点如下：

   ![image-20200218153200062](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200218153200062.png)



### 二、Out-Of-Bag (OOB) Estimate

1. 首先回顾一下bagging算法：

   ![image-20200218154816204](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200218154816204.png)



2. 我们通过随机取样的方法来获得$\widetilde{D_t}$，现在我们考虑没有被选择中的样本，在这里我们称之为**OOB examples**,我们对于$N'=N$情况下OOB的样本概率进行估计，

$$
(1-\frac1N)^N \approx  \frac1e
$$

3. 我们对于OOB和Validation做一个比较:

   ![image-20200218160158553](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200218160158553.png)

4. 我们可以通过衡量$E_{oob}$来衡量RF的效果，这种可以看作是RF的一个**self-validation**的优势！因此我们也可以利用$E_{oob}$来选择模型，一般情况下它甚至比一般的validation效果要好

   ![image-20200218160837651](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200218160837651.png)

### 三、Feature Selection

1. decision tree是一个具有内在特征选择机制的模型，这在大部分模型当中是很少出现的：

   ![image-20200218161217354](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200218161217354.png)

   可以达到摒弃不相关和多余特征的效果，类似于一种降维的方法

2. 总结一下决策树的优劣：

- 优势：

  - 高效：用简单的假设构成的预测

  - 泛化能力：摒弃了特征的噪声（不相关和多余的特征）

  - 可解释性：符合人类决策

- 劣势：

  - 计算力：训练过程时间长
  - 过拟合：特征选择过多
  - 解释性差：理论基础不坚固

3. <font color = red>**特征选择机制：重要性原则**，适用于**线性模型**，权重的大小代表着重要性</font>

   ![image-20200218162053195](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200218162053195.png)

   

4. <font color = red>**特征选择机制：全排列测试**，适用于**非线性模型**，去掉此特征后，表现的衰弱程度作为评判重要性的原则！</font>

   ![image-20200218162422338](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200218162422338.png)

5. 在原始的随机森林模型中我们采用的特征重要性度量方法：

   我们结合permutation作为重要性度量，利用OOB-Validation作为Error度量

### 四、Random Forest in Action

需要足够多的树来保证稳定性！