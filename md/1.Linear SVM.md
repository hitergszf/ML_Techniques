# Linear Support Vector Machine

1. 选取一种鲁棒性强的方法——在linear regression上做手脚

2. largest margin:

   <img src="C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200205234419590.png" alt="image-20200205234419590" style="zoom:75%;" />

<img src="C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200205234514797.png" alt="image-20200205234514797" style="zoom:65%;" />

3. distance(x,b,w),这里不能忽略bias
   $$
   distance(X,b,W) = \frac1{||W||}|W^Tx+b|
   $$
   
4. 数学建模

   ![image-20200205234902295](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200205234902295.png)



5. 由于成比例缩放的缘故：令
   $$
   y_n(W^TX_n+b)=1
   $$

6. necessary constraints:
   $$
   y_n(W^TX_n+b)\geq1
   $$
   通过反证法可以证明(2)(3)互为充要条件，其中用到$$max \frac1{||W||} $$

<img src="C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200205235521174.png" alt="image-20200205235521174" style="zoom:140%;" />

QP problem， 一个二次规划问题

![image-20200205235626050](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200205235626050.png)

![image-20200205235639250](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200205235639250.png)

7. 一些优势：

   配合feature transformation会特别强大，鲁棒性和泛化能力都可以保证

![image-20200205235805659](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20200205235805659.png)

